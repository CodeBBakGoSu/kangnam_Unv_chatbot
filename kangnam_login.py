import requests
from bs4 import BeautifulSoup
import json

# 1ï¸âƒ£ ì‚¬ìš©ì ì…ë ¥ (ë³´ì•ˆì„ ìœ„í•´ inputìœ¼ë¡œ ë°›ê¸°)
username = input("í•™êµ ì•„ì´ë””: ")
password = input("í•™êµ ë¹„ë°€ë²ˆí˜¸: ")

# 2ï¸âƒ£ ë¡œê·¸ì¸ ì„¸ì…˜ ì¤€ë¹„
session = requests.Session()
login_url = "https://ecampus.kangnam.ac.kr/login/index.php"

# 3ï¸âƒ£ ë¡œê·¸ì¸ POST ìš”ì²­
payload = {
    'username': username,
    'password': password
}
res = session.post(login_url, data=payload)
if res.status_code != 200 or "ë¡œê·¸ì•„ì›ƒ" not in res.text:
    print("ë¡œê·¸ì¸ ì‹¤íŒ¨ âŒ")
    exit()

print("âœ… ë¡œê·¸ì¸ ì„±ê³µ!")

# 4ï¸âƒ£ ê°•ì˜ ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ ìš”ì²­
course_list_url = "https://ecampus.kangnam.ac.kr/"
res = session.get(course_list_url)
soup = BeautifulSoup(res.text, "html.parser")

# 5ï¸âƒ£ ê°•ì˜ ì •ë³´ ìˆ˜ì§‘
courses = []
for course_div in soup.select("ul.my-course-lists > li.course_label_re_03"):
    title_tag = course_div.select_one(".course-title h3")
    prof_tag = course_div.select_one(".course-title p.prof")
    link_tag = course_div.select_one("a.course_link")

    if title_tag and link_tag:
        courses.append({
            "title": title_tag.text.strip(),
            "professor": prof_tag.text.strip() if prof_tag else "",
            "url": link_tag['href']
        })

# ê²°ê³¼ ì €ì¥ì„ ìœ„í•œ ë”•ì…”ë„ˆë¦¬
results = {"user": {}, "courses": []}

# 6ï¸âƒ£ ì‚¬ìš©ì ì´ë¦„ ë° í•™ë¶€ ì •ë³´ ìˆ˜ì§‘
user_info_tag = soup.select_one("div.user-info-picture")
if user_info_tag:
    user_name_tag = user_info_tag.select_one("h4")
    user_dept_tag = user_info_tag.select_one("p.department")
    user_name = user_name_tag.text.strip() if user_name_tag else "ì´ë¦„ ì—†ìŒ"
    user_dept = user_dept_tag.text.strip() if user_dept_tag else "í•™ë¶€ ì •ë³´ ì—†ìŒ"
    results["user"] = {"name": user_name, "department": user_dept}
    print(f"\nğŸ‘¤ ì‚¬ìš©ì: {user_name}")
    print(f"ğŸ« í•™ë¶€: {user_dept}")
else:
    print("â— ì‚¬ìš©ì ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# âœ… íŠ¹ì • ê°•ì˜ í˜ì´ì§€ì—ì„œ ì£¼ì°¨ë³„ í™œë™ ì •ë³´ ìˆ˜ì§‘ (ì˜ˆ: ë°ì´í„°ìˆ˜ì§‘ê³¼ì²˜ë¦¬)
def fetch_course_weeks(course_url):
    week_info = []
    res = session.get(course_url)
    soup = BeautifulSoup(res.text, "html.parser")
    weeks = soup.select("ul.weeks li.section.main.clearfix")
    
    for week in weeks:
        title = week.get("aria-label", "").strip()
        activities = []
        for act in week.select("li.activity"):
            name = act.select_one(".instancename")
            if name:
                activities.append(name.text.strip().replace("íŒŒì¼", "").replace("ê²Œì‹œíŒ", "").replace("ê³¼ì œ", "").strip())
        week_info.append({"title": title, "activities": activities})
        
        # ê³¼ì œê°€ ìˆë‹¤ë©´ ë§í¬ë¥¼ ê°€ì ¸ì™€ ìƒíƒœ í™•ì¸
        for act in week.select("li.activity.assign a"):
            href = act.get("href")
            if href:
                assignment_status = fetch_assignment_status(href)
                week_info[-1]["assignment_status"] = assignment_status

    video_attendance_status = fetch_video_attendance_status(course_url)
    attendance_summary = fetch_attendance_summary(course_url)
    
    return {"weeks": week_info, "video_attendance": video_attendance_status, "attendance_summary": attendance_summary}

def fetch_assignment_status(assign_url):
    res = session.get(assign_url)
    soup = BeautifulSoup(res.text, "html.parser")
    table = soup.select_one(".submissionstatustable table")
    
    if not table:
        return {"error": "ê³¼ì œ ì œì¶œ ì •ë³´ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
    rows = table.select("tr")
    status_info = {}
    for row in rows:
        cells = row.select("td")
        if len(cells) == 2:
            key = cells[0].text.strip()
            val = cells[1].text.strip()
            status_info[key] = val
    
    return status_info

def fetch_attendance_summary(course_url):
    res = session.get(course_url)
    soup = BeautifulSoup(res.text, "html.parser")
    summary = soup.select("ul.attendance li.attendance_section")
    attendance_info = []

    for week in summary:
        week_num = week.select_one("p.sname").text.strip()
        status = week.text.replace(week_num, "").strip()
        attendance_info.append({"week": week_num, "status": status if status else 'ê²°ì„ ë˜ëŠ” ë¯¸ê¸°ë¡'})

    return attendance_info

def fetch_video_attendance_status(course_url):
    res = session.get(course_url)
    soup = BeautifulSoup(res.text, "html.parser")
    video_blocks = soup.select("li.activity.vod .activityinstance")
    video_info = []

    for video in video_blocks:
        title_tag = video.select_one("span.instancename")
        time_tag = video.select_one("span.text-info")
        period_tag = video.select_one("span.text-ubstrap")
        video_url_tag = video.select_one("a")

        title = title_tag.text.strip() if title_tag else "(ì œëª© ì—†ìŒ)"
        time = time_tag.text.strip() if time_tag else "ì¬ìƒ ì‹œê°„ ì •ë³´ ì—†ìŒ"
        period = period_tag.text.strip() if period_tag else "ìˆ˜ê°• ê¸°ê°„ ì •ë³´ ì—†ìŒ"
        url = video_url_tag["href"] if video_url_tag else "ë§í¬ ì—†ìŒ"

        video_info.append({"title": title, "url": url, "time": time, "period": period})

    return video_info

def fetch_course_notices(course_url):
    res = session.get(course_url)
    soup = BeautifulSoup(res.text, "html.parser")
    notice_box = soup.select_one("div.upcommings ul")
    notices_info = []

    if not notice_box:
        return notices_info

    notices = notice_box.select("li > a")
    for notice in notices:
        title = notice.select_one("h5").get("title", "").strip()
        link = notice["href"]
        notices_info.append({"title": title, "link": link})

    return notices_info

def fetch_notice_detail(notice_url):
    res = session.get(notice_url)
    soup = BeautifulSoup(res.text, "html.parser")

    subject = soup.select_one("div.subject h3")
    writer = soup.select_one("div.writer")
    date = soup.select_one("div.date")
    views = soup.select_one("div.hit")
    content = soup.select_one("div.content .text_to_html")

    notice_detail = {
        "subject": subject.text.strip() if subject else 'N/A',
        "writer": writer.text.strip().replace('ì‘ì„±ì :', '').strip() if writer else 'N/A',
        "date": date.text.strip().replace('ì‘ì„±ì¼ :', '').strip() if date else 'N/A',
        "views": views.text.strip().replace('ì¡°íšŒìˆ˜ :', '').strip() if views else 'N/A',
        "content": [line for line in content.stripped_strings] if content else []
    }
    
    return notice_detail

# ğŸ”„ ëª¨ë“  ê°•ì˜ì—ì„œ ì£¼ì°¨ë³„ í™œë™ ì •ë³´ ìˆ˜ì§‘
course_results = []
for course in courses:
    course_data = {
        "title": course['title'],
        "professor": course['professor'],
        "weeks": [],
        "notices": []
    }
    course_weeks_info = fetch_course_weeks(course['url'])
    course_data["weeks"] = course_weeks_info
    course_notices_info = fetch_course_notices(course['url'])
    detailed_notices = []
    for notice in course_notices_info:
        detail = fetch_notice_detail(notice["link"])
        detailed_notices.append({**notice, "detail": detail})
    course_data["notices"] = detailed_notices
    course_results.append(course_data)

results["courses"] = course_results

# JSON íŒŒì¼ë¡œ ì €ì¥
with open("kangnam_courses.json", "w", encoding="utf-8") as f:
    json.dump(results, f, ensure_ascii=False, indent=2)